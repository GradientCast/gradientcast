{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# DensityAD Quickstart\n\n**DensityAD** (GradientCastDenseAD) uses advanced density-based pattern analysis to detect anomalies with severity classification.\n\n**Best for:** Complex patterns, severity-based alerting, multi-feature analysis.\n\n**How it works:**\n1. Engineers features from historical data (rolling stats, z-scores, lags)\n2. Applies intelligent density analysis to detect pattern-based outliers\n3. Classifies severity (low, medium, high, critical)\n4. Filters noise with contiguous anomaly requirements\n\n**Important:** Historical data is required for context and feature engineering, but anomaly detection is performed only on the latest data point(s) in the time series you provide."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../..')\n",
    "\n",
    "from gradientcast import GradientCastDenseAD\n",
    "from utils.synthetic_data import generate_ad_payload_data\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Replace with your API key\n",
    "GRADIENTCAST_API_KEY = \"your-api-key-here\"\n",
    "\n",
    "dense_ad = GradientCastDenseAD(api_key=GRADIENTCAST_API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Basic Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Generate sample data with anomalies\n# Earlier points serve as historical context, latest point(s) are evaluated\ndata = generate_ad_payload_data(n_points=100, inject_anomalies=True)\n\n# Detect anomalies - uses history for context, evaluates latest point(s)\nresult = dense_ad.detect(data)\n\nprint(f\"Alert Status: {result.alert_status}\")\nprint(f\"Alert Severity: {result.alert_severity}\")\nprint(f\"Total points in timeline: {len(result.timeline)}\")\nprint(f\"Confirmed anomalies: {len(result.anomalies)}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Understanding the Response\n",
    "\n",
    "DensityAD provides rich anomaly metadata including severity levels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Examine anomaly details\nprint(\"Anomaly Details:\")\nfor point in result.anomalies[:5]:  # First 5\n    mag = point.magnitude\n    print(f\"\\n  Timestamp: {point.timestamp}\")\n    print(f\"  Value: {point.value:,}\")\n    print(f\"  Severity: {mag.severity.upper()}\")\n    print(f\"  Anomaly Score: {mag.anomaly_score:.2f}\")\n    print(f\"  Normalized Score: {mag.normalized_score:.1f}/100\")\n    print(f\"  Z-Score (24h): {mag.zscore_24h:.2f}\" if mag.zscore_24h else \"  Z-Score: N/A\")\n    print(f\"  Deviation: {mag.deviation_pct:+.1f}%\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Severity distribution\n",
    "severity_counts = {}\n",
    "for point in result.anomalies:\n",
    "    sev = point.magnitude.severity\n",
    "    severity_counts[sev] = severity_counts.get(sev, 0) + 1\n",
    "\n",
    "print(\"Severity Distribution:\")\n",
    "for sev in ['low', 'medium', 'high', 'critical']:\n",
    "    count = severity_counts.get(sev, 0)\n",
    "    if count > 0:\n",
    "        print(f\"  {sev.capitalize()}: {count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Visualizing Results\n",
    "\n",
    "Color-coded by severity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract data for plotting\n",
    "values = [p.value for p in result.timeline]\n",
    "\n",
    "# Color mapping for severity\n",
    "severity_colors = {\n",
    "    'none': 'blue',\n",
    "    'low': 'yellow',\n",
    "    'medium': 'orange',\n",
    "    'high': 'red',\n",
    "    'critical': 'darkred'\n",
    "}\n",
    "\n",
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "# Plot time series\n",
    "plt.plot(values, 'b-', alpha=0.5, lw=1, label='Values')\n",
    "\n",
    "# Plot anomalies by severity\n",
    "for sev in ['low', 'medium', 'high', 'critical']:\n",
    "    sev_points = [(i, p.value) for i, p in enumerate(result.timeline) \n",
    "                  if p.confirmed_anomaly and p.magnitude.severity == sev]\n",
    "    if sev_points:\n",
    "        x, y = zip(*sev_points)\n",
    "        plt.scatter(x, y, c=severity_colors[sev], s=100, zorder=5, \n",
    "                    edgecolors='black', linewidths=1, label=f'{sev.capitalize()}')\n",
    "\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Value')\n",
    "plt.title('DensityAD: Anomalies by Severity')\n",
    "plt.legend(loc='upper right')\n",
    "plt.grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n## Raw vs Confirmed Anomalies\n\nDensityAD distinguishes between initial detection (raw) and filtered results (confirmed)."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Count raw vs confirmed\nraw_count = sum(1 for p in result.timeline if p.raw_anomaly)\nconfirmed_count = sum(1 for p in result.timeline if p.confirmed_anomaly)\n\nprint(f\"Raw anomalies (initial detection): {raw_count}\")\nprint(f\"Confirmed anomalies (after filtering): {confirmed_count}\")\nprint(f\"Filtered out: {raw_count - confirmed_count}\")\n\n# Filtering reasons:\n# - Valley threshold: Values too low to be meaningful\n# - Contiguous check: Single isolated points filtered out"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize raw vs confirmed\n",
    "plt.figure(figsize=(14, 5))\n",
    "\n",
    "plt.plot(values, 'b-', alpha=0.5, lw=1)\n",
    "\n",
    "# Raw anomalies (light)\n",
    "raw_only = [(i, p.value) for i, p in enumerate(result.timeline) \n",
    "            if p.raw_anomaly and not p.confirmed_anomaly]\n",
    "if raw_only:\n",
    "    x, y = zip(*raw_only)\n",
    "    plt.scatter(x, y, c='lightblue', s=80, alpha=0.6, label='Raw (filtered out)')\n",
    "\n",
    "# Confirmed anomalies\n",
    "confirmed = [(i, p.value) for i, p in enumerate(result.timeline) if p.confirmed_anomaly]\n",
    "if confirmed:\n",
    "    x, y = zip(*confirmed)\n",
    "    plt.scatter(x, y, c='red', s=100, zorder=5, edgecolors='darkred', \n",
    "                linewidths=1.5, label='Confirmed')\n",
    "\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Value')\n",
    "plt.title('Raw vs Confirmed Anomalies')\n",
    "plt.legend()\n",
    "plt.grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Convert to DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to pandas DataFrame\n",
    "df = result.to_dataframe()\n",
    "print(\"DataFrame columns:\")\n",
    "print(list(df.columns))\n",
    "print()\n",
    "\n",
    "# Show anomalies only\n",
    "anomalies_df = df[df['confirmed_anomaly'] == True]\n",
    "print(f\"Anomalies DataFrame ({len(anomalies_df)} rows):\")\n",
    "anomalies_df[['timestamp', 'value', 'severity', 'normalized_score', 'deviation_pct']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n## Key Concepts\n\n### Severity Levels\n\n| Severity | Meaning | Action |\n|----------|---------|--------|\n| **Low** | Minor deviation | Log and monitor |\n| **Medium** | Noticeable issue | Investigate |\n| **High** | Significant problem | Alert on-call |\n| **Critical** | Severe anomaly | Immediate action |\n\n### Magnitude Metrics\n\n| Metric | Description |\n|--------|------------|\n| `anomaly_score` | Raw density score (higher = more anomalous) |\n| `normalized_score` | 0-100 scale for easy comparison |\n| `zscore_24h` | Standard deviations from 24h mean |\n| `deviation_pct` | Percentage deviation from expected |\n\n### When to Use DensityAD\n\n**Good for:**\n- Complex, irregular patterns\n- Need for severity classification\n- Multi-feature analysis\n\n**Consider PulseAD instead for:**\n- Simple threshold-based detection\n- Predictable trend deviations\n- Lower latency requirements\n\n**Next:** [Tuning Parameters](02_tuning.ipynb)"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}