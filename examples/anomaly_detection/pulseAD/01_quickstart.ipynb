{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# PulseAD Quickstart\n\n**PulseAD** (GradientCastPulseAD) detects anomalies by identifying significant deviations from expected behavior.\n\n**Best for:** Detecting when metrics deviate significantly from expected patterns.\n\n**How it works:**\n1. Uses historical data as context to learn expected behavior patterns\n2. Evaluates only the most recent data point(s) against those expectations\n3. Flags points exceeding threshold deviations\n\n**Important:** Historical data is required for context, but anomaly detection is performed only on the latest data point(s) in the time series you provide."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import sys\nsys.path.append('../..')\n\nfrom gradientcast import GradientCastPulseAD\nfrom utils.synthetic_data import generate_timestamps\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n# Replace with your API key\nGRADIENTCAST_API_KEY = \"your-api-key-here\"\n\nad = GradientCastPulseAD(api_key=GRADIENTCAST_API_KEY)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Basic Detection\n",
    "\n",
    "Detect anomalies in a simple time series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Sample data: first 7 points provide historical context,\n# the last point (850000) is evaluated for anomalies\ndata = [\n    {\"timestamp\": \"12/01/2024, 12:00 PM\", \"value\": 1500000},  # Historical context\n    {\"timestamp\": \"12/01/2024, 01:00 PM\", \"value\": 1520000},  # Historical context\n    {\"timestamp\": \"12/01/2024, 02:00 PM\", \"value\": 1510000},  # Historical context\n    {\"timestamp\": \"12/01/2024, 03:00 PM\", \"value\": 1530000},  # Historical context\n    {\"timestamp\": \"12/01/2024, 04:00 PM\", \"value\": 1525000},  # Historical context\n    {\"timestamp\": \"12/01/2024, 05:00 PM\", \"value\": 1515000},  # Historical context\n    {\"timestamp\": \"12/01/2024, 06:00 PM\", \"value\": 1540000},  # Historical context\n    {\"timestamp\": \"12/01/2024, 07:00 PM\", \"value\": 850000},   # <-- Evaluated for anomaly (~45% drop)\n]\n\n# Detect anomalies - uses history for context, evaluates latest point(s)\nresult = ad.detect({\"user_count\": data})\n\nprint(f\"Anomalies detected: {result.has_anomaly}\")\nprint(f\"Number of anomalies: {len(result.anomalies)}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine the anomalies\n",
    "for anomaly in result.anomalies:\n",
    "    print(f\"\\nAnomaly at {anomaly.timestamp}:\")\n",
    "    print(f\"  Actual value:    {anomaly.actual_value:,}\")\n",
    "    print(f\"  Predicted value: {anomaly.predicted_value:,.0f}\")\n",
    "    print(f\"  Delta:           {anomaly.delta:,.0f}\")\n",
    "    print(f\"  Percent delta:   {anomaly.percent_delta}\")\n",
    "    print(f\"  Threshold:       {anomaly.threshold}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Understanding the Response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# All results (anomalies and non-anomalies)\nprint(\"All detection results:\")\nfor r in result.results:\n    status = \"ANOMALY\" if r.is_anomaly else \"Normal\"\n    print(f\"  {r.timestamp}: {r.actual_value:,} ({status})\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to DataFrame for analysis\n",
    "df = result.to_dataframe()\n",
    "print(\"\\nDataFrame columns:\", list(df.columns))\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Visualizing Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Extract values for plotting\ntimestamps = [d[\"timestamp\"].split(\",\")[1].strip() for d in data]\nvalues = [d[\"value\"] for d in data]\nanomaly_mask = [r.is_anomaly for r in result.results]\n\nplt.figure(figsize=(12, 5))\n\n# Plot the time series\nplt.plot(timestamps, values, 'b-o', markersize=8, label='Actual Values')\n\n# Highlight anomalies\nanomaly_x = [t for t, m in zip(timestamps, anomaly_mask) if m]\nanomaly_y = [v for v, m in zip(values, anomaly_mask) if m]\nplt.scatter(anomaly_x, anomaly_y, c='red', s=200, zorder=5, \n            label='Anomaly', edgecolors='darkred', linewidths=2)\n\n# Add expected values line\nexpected = [r.predicted_value for r in result.results]\nplt.plot(timestamps, expected, 'g--', alpha=0.7, label='Expected')\n\nplt.xlabel('Time')\nplt.ylabel('Value')\nplt.title('PulseAD: Deviation-Based Anomaly Detection')\nplt.legend()\nplt.xticks(rotation=45)\nplt.grid(alpha=0.3)\nplt.tight_layout()\nplt.show()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Multi-Dimension Detection\n",
    "\n",
    "Monitor multiple metrics simultaneously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate timestamps\n",
    "timestamps = generate_timestamps(10, freq='H')\n",
    "\n",
    "# Create multi-dimensional data\n",
    "multi_data = {\n",
    "    \"api_requests\": [\n",
    "        {\"timestamp\": ts, \"value\": int(1000000 + np.random.normal(0, 50000))}\n",
    "        for ts in timestamps[:-1]\n",
    "    ] + [{\"timestamp\": timestamps[-1], \"value\": 400000}],  # Anomaly\n",
    "    \n",
    "    \"active_users\": [\n",
    "        {\"timestamp\": ts, \"value\": int(500000 + np.random.normal(0, 25000))}\n",
    "        for ts in timestamps  # No anomaly here\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Detect across all dimensions\n",
    "result = ad.detect(multi_data)\n",
    "\n",
    "print(f\"Total anomalies: {len(result.anomalies)}\")\n",
    "for a in result.anomalies:\n",
    "    print(f\"  {a.dimension}: {a.percent_delta} deviation at {a.timestamp}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n## Key Concepts\n\n### Detection Logic\n\nAn anomaly is flagged when **both** conditions are met:\n\n1. **Percent deviation exceeds threshold** (default: 15%)\n   ```\n   |actual - expected| / expected > threshold\n   ```\n\n2. **Value exceeds minimum threshold** (default: 100,000)\n   - Filters out noise on low-volume metrics\n\n### When to Use PulseAD\n\n**Good for:**\n- Metrics with regular patterns\n- Detecting sudden drops or spikes\n- Monitoring user counts, traffic, revenue\n\n**Consider DensityAD instead for:**\n- Highly irregular patterns\n- Need for severity classification\n- Pattern-based anomalies\n\n**Next:** [Tuning Thresholds](02_tuning.ipynb)"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}